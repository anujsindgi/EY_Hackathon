{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12038e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/qubit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2dc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2137aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing DataFrame\n",
    "raw_dataframe = pd.read_excel(\"Datasets _ NLP based tagging solution078466f.xlsx\",sheet_name = None)\n",
    "\n",
    "training_data = raw_dataframe['Training Data ']\n",
    "tag_frame = raw_dataframe['Keywords for tagging']\n",
    "\n",
    "Bus_Exp_Tags = tag_frame['Keywords for Business Exception']\n",
    "Bus_Exp_Tags = Bus_Exp_Tags.iloc[0:8]\n",
    "Sof_Exp_Tags = tag_frame['Keywords for System Exception']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5bdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Data\n",
    "Bus_Exp_Tags.apply(clean_text)\n",
    "Sof_Exp_Tags.apply(clean_text)\n",
    "Bus_Exp_Tags = Bus_Exp_Tags.unique()\n",
    "Sof_Exp_Tags = Sof_Exp_Tags.unique()\n",
    "\n",
    "Train_data = training_data['Exception (input)'].apply(clean_text)\n",
    "Actual_Class = training_data['Exception Category (ouput)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d8c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing StopWords\n",
    "Words=[]\n",
    "for line in Train_data:\n",
    "    text_tokens = line.split()\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    Words.append(tokens_without_sw)\n",
    "\n",
    "Words_BE = []\n",
    "Words_SE = []\n",
    "\n",
    "for line in Bus_Exp_Tags:\n",
    "    text_tokens = line.lower().split()\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    Words_BE += tokens_without_sw\n",
    "\n",
    "for line in Sof_Exp_Tags:\n",
    "    text_tokens = line.lower().split()\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    Words_SE += tokens_without_sw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbda6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning weights to tags inversely proportional to their frequency\n",
    "ALL_WORDS = {}\n",
    "BE_WORDS = {}\n",
    "SE_WORDS = {}\n",
    "\n",
    "for line in Words:\n",
    "    for tok in line:\n",
    "        if tok in ALL_WORDS:\n",
    "            ALL_WORDS[tok] += 1\n",
    "        else :\n",
    "            ALL_WORDS[tok] = 1\n",
    "\n",
    "\n",
    "for word in Words_BE:\n",
    "    if word in ALL_WORDS :\n",
    "        BE_WORDS[word] = ALL_WORDS[word]\n",
    "    else:\n",
    "        BE_WORDS[word] = 0\n",
    "        \n",
    "for word in Words_SE:\n",
    "    if word in ALL_WORDS :\n",
    "        SE_WORDS[word] = ALL_WORDS[word]\n",
    "    else:\n",
    "        SE_WORDS[word] = 0\n",
    "max_count_BE = max(BE_WORDS.values())\n",
    "max_count_SE = max(SE_WORDS.values())\n",
    "\n",
    "for word in BE_WORDS:\n",
    "    BE_WORDS[word]=max_count_BE-BE_WORDS[word]\n",
    "    \n",
    "for word in SE_WORDS:\n",
    "    SE_WORDS[word]=max_count_SE-SE_WORDS[word]+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87507ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rule Based Classification\n",
    "Pred_Class = []\n",
    "i=0\n",
    "for line in Words:\n",
    "    count_BE=0\n",
    "    count_SE=0\n",
    "\n",
    "    \n",
    "    for keyword in Words_BE:\n",
    "        if keyword in line:\n",
    "#             count_BE+=1\n",
    "            count_BE+=BE_WORDS[keyword]\n",
    "            \n",
    "    for keyword in Words_SE:\n",
    "        if keyword in line:\n",
    "#             count_SE+=1\n",
    "            count_SE+=SE_WORDS[keyword]\n",
    "    \n",
    "    if count_BE >= count_SE:\n",
    "        Pred_Class.append(\"Business Exception\")\n",
    "    else:\n",
    "        Pred_Class.append(\"System Exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61fff35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.61702127659575\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "count = 0\n",
    "for i in range(0,len(Pred_Class)):\n",
    "    if Pred_Class[i] == Actual_Class[i]:\n",
    "        count+=1\n",
    "print(count*100.0/len(Pred_Class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
